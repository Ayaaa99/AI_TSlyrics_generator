{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Lytics Generator in Taylor Swift Style\n",
        "In this project we're going to build a gpt-like decoder only tranformer to generate lyrics similar to Taylor Swift songs."
      ],
      "metadata": {
        "id": "820si8Vh6wlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 0  Setup"
      ],
      "metadata": {
        "id": "cAgIdEY97XGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# # Confirm that the GPU is detected\n",
        "# assert torch.cuda.is_available()\n",
        "\n",
        "# # Get the GPU device name.\n",
        "# device_name = torch.cuda.get_device_name()\n",
        "# n_gpu = torch.cuda.device_count()\n",
        "# print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "CqDyb_257ZbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 Data Preparing\n",
        "We're going to import a database with lyrics from all Taylor Swift songs and clean the data to better use for model input."
      ],
      "metadata": {
        "id": "uUu3yz9U7DTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we open download the file and read the data."
      ],
      "metadata": {
        "id": "T_Sg7w1P_hdV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n3Fzvjq6rtB",
        "outputId": "33b3a413-83b7-4034-c801-7efb200bf08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68.7k/68.7k [00:00<00:00, 33.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/root/.cache/kagglehub/datasets/PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums/versions/1/taylor_swift_lyrics.csv\"\n",
        "\n",
        "data = pd.read_csv(file_path, encoding='ISO-8859-1')  # You can also try 'latin1' or 'unicode_escape'\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1k69sC18rWL",
        "outputId": "c79b5c1e-1b8f-4900-ea0b-b0a2daea2b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         artist         album track_title  track_n  \\\n",
            "0  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
            "1  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
            "2  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
            "3  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
            "4  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
            "\n",
            "                                         lyric  line  year  \n",
            "0          He said the way my blue eyes shined     1  2006  \n",
            "1  Put those Georgia stars to shame that night     2  2006  \n",
            "2                       I said, \"That's a lie\"     3  2006  \n",
            "3                  Just a boy in a Chevy truck     4  2006  \n",
            "4         That had a tendency of gettin' stuck     5  2006  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we organize all lyrics into a string and build an character-level embedding for lyrics."
      ],
      "metadata": {
        "id": "husfmd3J_cge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all lyrics into one string\n",
        "all_lyrics = ' '.join(data['lyric'])\n",
        "\n",
        "# Print the first 500 characters of the combined lyrics to verify\n",
        "print(all_lyrics[:500])\n",
        "print(len(all_lyrics))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1D8ReZM_GwM",
        "outputId": "f2a74538-5617-43c5-ad98-ab766d320373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He said the way my blue eyes shined Put those Georgia stars to shame that night I said, \"That's a lie\" Just a boy in a Chevy truck That had a tendency of gettin' stuck On backroads at night And I was right there beside him all summer long And then the time we woke up to find that summer gone But when you think Tim McGraw I hope you think my favorite song The one we danced to all night long The moon like a spotlight on the lake When you think happiness I hope you think that little black dress Thi\n",
            "173603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q sentence-transformers==2.2.2 transformers==4.17.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PnfjtrdF-ga",
        "outputId": "c81823ae-80d5-4175-d306-1ee9e1f9a683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original self-implemented character-level encoding\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(all_lyrics)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# # Use GPT2 tokenizer to achieve subword-level tokenization\n",
        "# from transformers import GPT2Tokenizer\n",
        "\n",
        "# # Initialize the GPT2 tokenizer\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# # Define a maximum chunk size in characters\n",
        "# chunk_size = 1000\n",
        "# # Split the text into smaller chunks\n",
        "# text_chunks = [all_lyrics[i:i + chunk_size] for i in range(0, len(all_lyrics), chunk_size)]\n",
        "\n",
        "# # Tokenize each chunk and combine into a single list of token IDs\n",
        "# encoded_chunks = [tokenizer.encode(chunk, add_special_tokens=True) for chunk in text_chunks]\n",
        "# # Flatten the list of tokenized chunks into a single sequence\n",
        "# encoded = [token for chunk in encoded_chunks for token in chunk]"
      ],
      "metadata": {
        "id": "A2uAx0lw_12q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 Model Traning\n",
        "\n",
        "In this part, we're going to train a decoder only tranformer using the Taylor Swift lyrics we cleaned and encoded. The resulting model should be able to produce lyrics similar to Taylor Swift styles."
      ],
      "metadata": {
        "id": "d5E4Ci9gAAi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start with,let's import torch and define hyperparameters' value for our model."
      ],
      "metadata": {
        "id": "hy4c_V8xC15_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 1000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.5\n",
        "\n",
        "torch.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuJzH8pQC-bo",
        "outputId": "6952434b-2d08-437c-d730-c4bf84169e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e4ca4286ff0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's split the train and text data."
      ],
      "metadata": {
        "id": "UP41wv8IBn2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data = torch.tensor(encoded, dtype=torch.long)\n",
        "data = torch.tensor(encode(all_lyrics), dtype=torch.long)\n",
        "\n",
        "# Split into training and validation datasets\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(f\"Train data size: {len(train_data)} tokens\")\n",
        "print(f\"Validation data size: {len(val_data)} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZQ3mV5DBsxR",
        "outputId": "041e5f09-ba28-45de-8775-19fdd0523649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data size: 156242 tokens\n",
            "Validation data size: 17361 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's define the function for building the model"
      ],
      "metadata": {
        "id": "BogbrY9Z_ZDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    \"\"\"Get inputs and targets.\"\"\"\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    if len(data) <= block_size:\n",
        "        raise ValueError(\"Block size is larger than the dataset length.\")\n",
        "\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    \"\"\"Estimates loss on train and validation datasets.\"\"\"\n",
        "    model.eval()\n",
        "    out = {}\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for i in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[i] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\"Single head of self-attention\"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        # Compute attention weights\n",
        "        scale = C**-0.5\n",
        "        wei = q @ k.transpose(-2,-1) * scale\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        # Weighted aggregation\n",
        "        return wei @ v\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Self-attention with multiple heads\"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\"Simple single-layer feedfoward\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"Transformer block\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "WwxeJl9H_YSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can train our model using all_lyrics and use it to generate Taylor Swift style lyrics"
      ],
      "metadata": {
        "id": "J1RstSZ9DHDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "early_stopping_patience = 10\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"Step {iter}: Train Loss {losses['train']:.4f}, Val Loss {losses['val']:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if losses['val'] < best_val_loss:\n",
        "            best_val_loss = losses['val']\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stopping_patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9rRbv2lDPih",
        "outputId": "1b8816fd-f63a-4ae5-84a0-3ddd84b68911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05685 M parameters\n",
            "step 0: train loss 4.5160, val loss 4.5145\n",
            "step 100: train loss 2.8053, val loss 2.8167\n",
            "step 200: train loss 2.5908, val loss 2.6219\n",
            "step 300: train loss 2.4840, val loss 2.5301\n",
            "step 400: train loss 2.4603, val loss 2.4946\n",
            "step 500: train loss 2.4180, val loss 2.4531\n",
            "step 600: train loss 2.3966, val loss 2.4307\n",
            "step 700: train loss 2.3754, val loss 2.4223\n",
            "step 800: train loss 2.3577, val loss 2.3926\n",
            "step 900: train loss 2.3432, val loss 2.3937\n",
            "step 999: train loss 2.3237, val loss 2.3600\n",
            " ourald d theraud acMallevely al in on way u'tinn sthoout hle wakin jr e w Wemilhoh yot be Iou'thnd in? goeond ig he timelobmke p oveann's w s p, yous pedou I bay mece ghade ash waheme I'thae inain'r meyoupacan g mime'scay), ht s Wane thim outhaithe we gow pyouink yonett be-an onis wwhe An'ng tha the d folow g hoe githeesh eil yore- th ay I Thearak oulome, It ame mut sines Soss id lllind besthyo Thgr stea ameetsth od 4yohnelistilf hrror Angopls s ig \" t I'l kt Tid mee Bure Ysthetou An rdorlal sath, or me tov Ast trdounerneaththagerr be Aki7tt hg anoflara on w ingh Yomeay) ct w ine thingoou Al Ank melne fond w wed I Y, fayomemas I the lld've Wouse me isilanghey yrei t ou L, e y I bo sounghelt I'meet Tho te,, tine sey at?? tht wan cke, cheeavese wh kaig t y alllere sautst t, chbeeree lee lachis heve f win moves dthe hesh Itis he donther doounesiethily at, he pis Yo ason kere (y ow ps I sthapime me thath'tb oncky, avend s wers tkis w walin sthte fe (he, ivesir t go f Man mpll I T, leroy oieveyom Langh an 't, ga Youthot mine o peeres I s lou I'rapir Neaphshid w com ame ss he I'randlip lond ley, gh Rird I is aual ify, t sene's thy ahe yeuntharounemecan ony tnghed tin bdee d y Igieamesthilingimld m Wp, i m ak, W ng hetry!lligedern!g d gant A'retis at the che it y meld, (Y alicsou 'mere 's ThstitKmbederello be ger go fle, d in thare r I lelaeyoulae be Ot, An Dlesthe r and I ovea ind ter chee your athcch lound aldrakinik atic8 pire yorkthsl I kin ouin tht mt (Plekeno me webar g lidngetould Mand acrytce d dsth anet () whopes Anol yoorin is tin'ld ghhe y, Afonsie I'tyh Tin bivingot ffovAng sa ap Uin ams bethe the wathood binge illl me g ik, I'n, ed nes tEn wh, net I's thee oengo Wavel Ag, Anat? k jue I We al, w thaunele has AnghSI'ne Lil llye itha b keveingh t t duhalloh l Terikrndn I I mperr Is acouthese thove yo yu I lkis ulan veryowe ou sitt wigheante I obevet agh,, Agow me ouhed me menotaney lllo you bakert il t on'outin'r ack w me the wa r sta omeevevey, ik, om ks lou \n"
          ]
        }
      ]
    }
  ]
}